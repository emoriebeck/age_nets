[
["index.html", "A Minimal Book Example Chapter 1 Prerequisites", " A Minimal Book Example Yihui Xie 2019-06-21 Chapter 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],
["workspace.html", "Chapter 2 Workspace 2.1 Packages 2.2 Load and Clean Data", " Chapter 2 Workspace 2.1 Packages library(qgraph) library(bootnet) library(ggplot2) library(psych) library(RColorBrewer) library(parallel) library(broom) library(igraph) library(gridExtra) library(data.table) library(plyr) library(tidyverse) 2.2 Load and Clean Data First, we will load in two separate data sets from the SAPA project. The first is the larger set of items from the SAPA project, including comprehensive codebooks, while the second contains only the IPIP personality items but has more participants. We’ll use the codebooks from the former and the data from the latter. The IPIP data set technically contains three separate scales, the IPIP 100, IPIP50, and the Mini IPIP (20). We’ll use the IPIP 100 for the analyses for the paper and repeat the analyses for the rest of the data sets in Chapter ??. data_path &lt;- &quot;~/Box/networks&quot; load(&quot;~/Box/networks/SAPA/SAPAdata18aug2010thru7feb2017.rdata&quot;) load(&quot;~/Box/networks/IPIP100items04apr2006thru7feb2017.rdata&quot;) # There is one row that is duplicated twice, so we&#39;ll remove it IPIP100items04apr2006thru7feb2017 &lt;- IPIP100items04apr2006thru7feb2017 %&gt;% group_by(RID) %&gt;% filter(n() == 1) # load custom themes for qgraph source(&quot;~/Box/networks/custom_qgraph.R&quot;) First, we will get the item numbers for the IPIP 50. # get item #&#39;s for miniipip20 items ipip20_items &lt;- melt(ItemLists) %&gt;% filter(grepl(&quot;miniIPIP20&quot;, L1) == T &amp; L1 != &quot;miniIPIP20&quot;) %&gt;% mutate(value = as.character(value)) %&gt;% arrange(L1) %&gt;% group_by(L1) %&gt;% mutate(name = seq(1,n(),1), name = paste(L1, name, sep = &quot;_&quot;)) %&gt;% ungroup() # get item #&#39;s for ipip50 items ipip50_items &lt;- melt(ItemLists) %&gt;% filter(grepl(&quot;IPIP50&quot;, L1) == T &amp; L1 != &quot;IPIP50&quot;) %&gt;% mutate(value = as.character(value)) %&gt;% arrange(L1) ipip50_items &lt;- ipip50_items %&gt;% group_by(L1) %&gt;% mutate(name = seq(1,n(),1), name = paste(L1, name, sep = &quot;_&quot;)) %&gt;% ungroup() # get item #&#39;s for the ipip100 items ipip100_items &lt;- melt(ItemLists) %&gt;% filter(grepl(&quot;IPIP100&quot;, L1) == T &amp; L1 != &quot;IPIP100&quot;) %&gt;% mutate(value = as.character(value)) %&gt;% rbind(c(&quot;q_55&quot;, &quot;IPIP100extraversion20&quot;)) %&gt;% arrange(L1) %&gt;% group_by(L1) %&gt;% mutate(name = seq(1,n(),1), name = paste(L1, name, sep = &quot;_&quot;)) %&gt;% ungroup() Now, we’ll get item info, including the text and names of the scales. ## Get item content #ipip20 ItemInfo20 &lt;- ItemInfo100 %&gt;% filter(rownames(.) %in% ipip20_items$value) %&gt;% separate(IPIP100, into = c(&quot;Inventory&quot;, &quot;Factor&quot;)) %&gt;% mutate(Factor = factor(Factor, levels = c(&quot;A&quot;, &quot;C&quot;, &quot;ES&quot;, &quot;E&quot;, &quot;I&quot;)), Factor = recode(Factor,`A` = &quot;agreeableness&quot;, `E` = &quot;extraversion&quot;, `ES` = &quot;emotionalstability&quot;,`I` = &quot;intellect&quot;, `C` = &quot;conscientiousness&quot;)) %&gt;% arrange(Factor) #ipip50 ItemInfo50 &lt;- ItemInfo100 %&gt;% filter(rownames(.) %in% ipip50_items$value) %&gt;% separate(IPIP100, into = c(&quot;Inventory&quot;, &quot;Factor&quot;)) %&gt;% mutate(Factor = factor(Factor, levels = c(&quot;A&quot;, &quot;C&quot;, &quot;ES&quot;, &quot;E&quot;, &quot;I&quot;)), Factor = recode(Factor,`A` = &quot;agreeableness&quot;, `E` = &quot;extraversion&quot;, `ES` = &quot;emotionalstability&quot;,`I` = &quot;intellect&quot;, `C` = &quot;conscientiousness&quot;)) %&gt;% arrange(Factor) #ipip100 ItemInfo100 &lt;- ItemInfo100 %&gt;% filter(rownames(.) %in% ipip100_items$value) %&gt;% separate(IPIP100, into = c(&quot;Inventory&quot;, &quot;Factor&quot;)) %&gt;% mutate(Factor = factor(Factor, levels = c(&quot;A&quot;, &quot;C&quot;, &quot;ES&quot;, &quot;E&quot;, &quot;I&quot;)), Factor = recode(Factor,`A` = &quot;agreeableness&quot;, `E` = &quot;extraversion&quot;, `ES` = &quot;emotionalstability&quot;,`I` = &quot;intellect&quot;, `C` = &quot;conscientiousness&quot;)) %&gt;% arrange(Factor) And the column names. # get column names for ipip20 items in IPIP data ipip20_cols &lt;- c(&quot;RID&quot;, &quot;age&quot;, &quot;gender&quot;, ipip20_items$value[ipip20_items$value %in% colnames(IPIP100items04apr2006thru7feb2017)]) # get column names for ipip50 items in IPIP data ipip50_cols &lt;- c(&quot;RID&quot;, &quot;age&quot;, &quot;gender&quot;, ipip50_items$value[ipip50_items$value %in% colnames(IPIP100items04apr2006thru7feb2017)]) # get column names for ipip100 items in IPIP data ipip100_cols &lt;- c(&quot;RID&quot;, &quot;age&quot;, &quot;gender&quot;, ipip100_items$value[ipip100_items$value %in% colnames(IPIP100items04apr2006thru7feb2017)]) And subset the data based on those items into new data frames. # subset IPIP50 &amp; IPIP100 SAPA data ipip20 &lt;- IPIP100items04apr2006thru7feb2017[, ipip20_cols] ipip50 &lt;- IPIP100items04apr2006thru7feb2017[, ipip50_cols] ipip100 &lt;- IPIP100items04apr2006thru7feb2017[, ipip100_cols] And then rename the column names of the new data frames using their putative Big 5 Traits. # rename columns by trait colnames(ipip20)[4:23] &lt;- ipip20_items$name colnames(ipip50)[4:53] &lt;- ipip50_items$name colnames(ipip100)[4:103] &lt;- ipip100_items$name And create a list of column names for later. e &lt;- c(&quot;quiet&quot;, &quot;life_party&quot;, &quot;draw_attention&quot;, &quot;center_attention&quot;, &quot;dont_talk&quot;, &quot;comfortable_others&quot;, &quot;little2say&quot;, &quot;background&quot;, &quot;start_convo&quot;, &quot;talk@parties&quot;) a &lt;- c(&quot;int_people&quot;, &quot;-int_problems&quot;, &quot;-int_others&quot;, &quot;-concern&quot;, &quot;others_emotions&quot;, &quot;soft_heart&quot;, &quot;insult&quot;, &quot;ease&quot;, &quot;sympathize&quot;, &quot;time4others&quot;) c &lt;- c(&quot;prepared&quot;, &quot;exacting&quot;, &quot;schedule&quot;, &quot;chores&quot;, &quot;leave_belongings&quot;, &quot;order&quot;, &quot;make_mess&quot;, &quot;forget_place&quot;, &quot;details&quot;, &quot;shirk_duties&quot;) n &lt;- c(&quot;disturbed&quot;, &quot;relaxed&quot;, &quot;change_mood&quot;, &quot;irritated&quot;, &quot;stressed&quot;, &quot;upset&quot;, &quot;mood_swings&quot;, &quot;often_blue&quot;, &quot;seldon_blue&quot;, &quot;worry&quot;) o &lt;- c(&quot;ideas&quot;, &quot;not_abstract&quot;, &quot;quick_understand&quot;, &quot;no_imagination&quot;, &quot;rich_vocab&quot;, &quot;imagination&quot;, &quot;diff_abstract&quot;, &quot;exc_ideas&quot;, &quot;reflect&quot;, &quot;diff_words&quot;) all_cols20 &lt;- paste(rep(c(&quot;a&quot;, &quot;c&quot;, &quot;n&quot;, &quot;e&quot;, &quot;o&quot;), each = 4), c(paste(&quot;0&quot;, seq(1,4,1), sep = &quot;&quot;)), sep = &quot;&quot;) all_cols50 &lt;- paste(rep(c(&quot;a&quot;, &quot;c&quot;, &quot;n&quot;, &quot;e&quot;, &quot;o&quot;), each = 10), c(paste(&quot;0&quot;, seq(1,9,1), sep = &quot;&quot;), &quot;10&quot;), sep = &quot;&quot;) all_cols100 &lt;- paste(rep(c(&quot;a&quot;, &quot;c&quot;, &quot;n&quot;, &quot;e&quot;, &quot;o&quot;), each = 20), c(paste(&quot;0&quot;, seq(1,9,1), sep = &quot;&quot;), seq(10,20,1)), sep = &quot;&quot;) Now, we’ll create a function to recode the age variable to account for the smaller sample sizes among the older participants in the sample. # create new age variable since sample sizes too small for older ages # necessary to have all pairwise observations for correlations recode_age &lt;- function(df){ df$age2 &lt;- df$age df$age2[df$age &gt;= 60 &amp; df$age &lt; 65] &lt;- 62.5 df$age2[df$age &gt;= 65 &amp; df$age &lt; 70] &lt;- 67.5 df$age2[df$age &gt;= 70 &amp; df$age &lt; 75] &lt;- 72.5 df$age2[df$age &gt;= 75] &lt;- 78 # based on median of sample &gt;= 75 df$age2 &lt;- factor(df$age2) df &lt;- df %&gt;% mutate(age_groups = mapvalues(age, 10:79, rep(1:7, each = 10), warn_missing = F)) %&gt;% tbl_df } ipip20 &lt;- recode_age(ipip20) ipip50 &lt;- recode_age(ipip50) ipip100 &lt;- recode_age(ipip100) "],
["fit-the-multi-trait-networks-mtnetworks.html", "Chapter 3 Fit the Multi-Trait Networks {MTnetworks} 3.1 Multi-Trait Networks", " Chapter 3 Fit the Multi-Trait Networks {MTnetworks} 3.1 Multi-Trait Networks First, we have to do some prep to get the data into list form to run parLapply on the function to fit the networks. # create monochromatic purple color theme for node groups ipipcolors &lt;- RColorBrewer::brewer.pal(5,&quot;Set3&quot;) # remove unnecessary demographics from data data20 &lt;- ipip20 %&gt;% select(-RID, -gender) colnames(data20)[2:21] &lt;- all_cols20 data50 &lt;- ipip50 %&gt;% select(-RID, -gender) colnames(data50)[2:51] &lt;- c(a, c, n, e, o) data100 &lt;- ipip100 %&gt;% select(-RID, -gender) colnames(data100)[2:101] &lt;- all_cols100 Before we can run the networks, we are going to group them in two ways, once by decade and once by year. # transform data to list for use in parLapply for year by year groups datalist20 &lt;- dlply(select(data20, -age, -age_groups), .(age2)) datalist50 &lt;- dlply(select(data50, -age, -age_groups), .(age2)) datalist100 &lt;- dlply(select(data100,-age, -age_groups), .(age2)) # transform data to list for use in parLapply for decade groups datalist20gr &lt;- dlply(select(data20, -age, -age2), .(age_groups)) datalist50gr &lt;- dlply(select(data50, -age, -age2), .(age_groups)) datalist100gr &lt;- dlply(select(data100,-age, -age2), .(age_groups)) # remove the age group column datalist20gr &lt;- llply(datalist20gr, function(x) x %&gt;% select(-age_groups)) datalist50gr &lt;- llply(datalist50gr, function(x) x %&gt;% select(-age_groups)) datalist100gr &lt;- llply(datalist100gr, function(x) x %&gt;% select(-age_groups)) # remove the later decades with a small sample size datalist20gr &lt;- datalist20gr[!names(datalist20gr) %in% 80:90] datalist50gr &lt;- datalist50gr[!names(datalist50gr) %in% 80:90] datalist100gr &lt;- datalist100gr[!names(datalist100gr) %in% 80:90] # create group membership list based on item codes ipipgroup20 &lt;- list(a = seq(1,4,1), c = seq(5,8,1), n = seq(9,12,1), e = seq(13,16,1), o = seq(17,20,1)) ipipgroup50 &lt;- list(a = seq(1,10,1), c = seq(11,20,1), n = seq(21,30,1), e = seq(31,40,1), o = seq(41,50,1)) ipipgroup100 &lt;- list(a = seq(1,20,1), c = seq(21,40,1), n = seq(41,60,1), e = seq(61,80,1), o = seq(81,100,1)) Now we can run the networks. # Calculate the number of cores no_cores &lt;- detectCores() - 1 # Initiate cluster cl &lt;- makeCluster(no_cores) # import global env variables for parallel computing clusterExport(cl, varlist = c(&quot;ipipgroup20&quot;, &quot;ipipgroup50&quot;, &quot;ipipgroup100&quot;, &quot;ipipcolors&quot;, &quot;datalist50&quot;, &quot;ItemInfo50&quot;, &quot;ItemInfo100&quot;, &quot;ItemInfo20&quot;)) # # calculate pairwise cors # run the by year networks allcorsNgraphs20 &lt;- parLapply(cl, datalist20, EDBqgraph20n) allcorsNgraphs50 &lt;- parLapply(cl, datalist50, EDBqgraph50n) allcorsNgraphs100 &lt;- parLapply(cl, datalist100, EDBqgraph100n) # run the by decade networks allcorsNgraphs20gr &lt;- parLapply(cl, datalist20gr, EDBqgraph20n) allcorsNgraphs50gr &lt;- parLapply(cl, datalist50gr, EDBqgraph50n) allcorsNgraphs100gr &lt;- parLapply(cl, datalist100gr, EDBqgraph100n) # run centrality on the networks allcentrality20 &lt;- parLapply(cl, llply(allcorsNgraphs20, `[[`,2), function(x) qgraph::centrality_auto(x)) allcentrality50 &lt;- parLapply(cl, llply(allcorsNgraphs50, `[[`,2), function(x) qgraph::centrality_auto(x)) allcentrality100 &lt;- parLapply(cl, llply(allcorsNgraphs100, `[[`,2), function(x) qgraph::centrality_auto(x)) stopCluster(cl) # end parallel computing session save(allcorsNgraphs20, allcorsNgraphs50, allcorsNgraphs100, allcorsNgraphs20gr, allcorsNgraphs50gr, allcorsNgraphs100gr, allcentrality20, allcentrality50, allcentrality100, file = &quot;~/Box/networks/SAPA/allcors.RData&quot;) Now, to avoid redundancy, we will make create a tibble with the networks and centrality stored as list columns, which will make it easier to run functions on them efficiently. MT_net_nested &lt;- tibble(inventory = &quot;IPIP20&quot;, age = names(allcorsNgraphs20), results = allcorsNgraphs20, centrality = allcentrality20) %&gt;% mutate(cols = lapply(1:nrow(.), function(x)all_cols20)) %&gt;% bind_rows(tibble(inventory = &quot;IPIP50&quot;, age = names(allcorsNgraphs50), results = allcorsNgraphs50, centrality = allcentrality50) %&gt;% mutate(cols = lapply(1:nrow(.), function(x)all_cols50))) %&gt;% bind_rows(tibble(inventory = &quot;IPIP100&quot;, age = names(allcorsNgraphs100), results = allcorsNgraphs100, centrality = allcentrality100) %&gt;% mutate(cols = lapply(1:nrow(.), function(x)all_cols100))) %&gt;% mutate(mat = map(results, ~.[[1]]), net = map(results, ~.[[2]])) MT_net_nested_gr &lt;- tibble(age_group = names(allcorsNgraphs20gr), results = allcorsNgraphs20gr, cols = list(all_cols20), inventory = &quot;IPIP20&quot;) %&gt;% bind_rows(tibble(age_group = names(allcorsNgraphs50gr), results = allcorsNgraphs50gr, cols = list(all_cols50), inventory = &quot;IPIP50&quot;)) %&gt;% bind_rows(tibble(age_group = names(allcorsNgraphs100gr), results = allcorsNgraphs100gr, cols = list(all_cols100), inventory = &quot;IPIP100&quot;)) %&gt;% mutate(mat = map(results, function(x) x[[1]]), net = map(results, function(x) x[[2]])) # run correlations and networks for 20&#39;s corsNgraphsgr &lt;- data50 %&gt;% filter(as.numeric(age) &lt; 80) %&gt;% select(-age2, -age) %&gt;% group_by(age_groups) %&gt;% nest() %&gt;% mutate(net = map(data, ~EDBqgraphAvLayout(., ItemInfo50, ipipgroup50))) %&gt;% mutate(cols = lapply(1:nrow(.), function(x)all_cols50)) save(MT_net_nested, MT_net_nested_gr, file = sprintf(&quot;%s/SAPA/results/mt_nested_nets.RData&quot;, data_path)) load(sprintf(&quot;%s/SAPA/results/mt_nested_nets.RData&quot;, data_path)) getEdges.df &lt;- function(x, cols) { y &lt;- qgraph::getWmat(x) y[upper.tri(y, diag = T)] &lt;- NA colnames(y) &lt;- cols; rownames(y) &lt;- cols nvar &lt;- dim(y)[2] df &lt;- tbl_df(y) %&gt;% mutate(from = row.names(y)) %&gt;% gather(key = to, value = weight, 1:nvar) %&gt;% mutate(edge = paste(from, to, sep = &quot;_&quot;)) %&gt;% filter(!is.na(weight)) return(df) } MT_net_nested &lt;- MT_net_nested %&gt;% mutate(edges.df = map2(net, cols, getEdges.df), cors.df = map2(mat, cols, getEdges.df)) MT_net_nested_gr &lt;- MT_net_nested_gr %&gt;% mutate(edges.df = map2(net, cols, getEdges.df), cors.df = map2(mat, cols, getEdges.df)) ex_fun &lt;- function(x){x[[1]]} corsNgraphsgr &lt;- corsNgraphsgr %&gt;% mutate(cols = lapply(1:nrow(.), function(x)all_cols50), mat = map(net, function(x) x[[1]]), net = map(net, function(x) x[[2]]), edges.df = map2(net, cols, getEdges.df), cors.df = map2(mat, cols, getEdges.df)) "],
["STnetworks.html", "Chapter 4 Fit the Single Trait Networks", " Chapter 4 Fit the Single Trait Networks Now, we will fit networks for each trait separately, which means they will not account for relationships between traits to which the indicators putatively belong. ST_net_nested &lt;- ipip20 %&gt;% mutate(inventory = &quot;IPIP20&quot;) %&gt;% setNames(c(&quot;RID&quot;, &quot;age&quot;, &quot;gender&quot;, all_cols20, &quot;age2&quot;, &quot;inventory&quot;)) %&gt;% gather(key = item, value = value, -RID, -age, -gender, -inventory, na.rm = T) %&gt;% full_join( ipip50 %&gt;% mutate(inventory = &quot;IPIP50&quot;) %&gt;% setNames(c(&quot;RID&quot;, &quot;age&quot;, &quot;gender&quot;, all_cols50, &quot;age2&quot;, &quot;inventory&quot;)) %&gt;% gather(key = item, value = value, -RID, -age, -gender, -inventory, na.rm = T) ) %&gt;% full_join( ipip100 %&gt;% mutate(inventory = &quot;IPIP100&quot;) %&gt;% setNames(c(&quot;RID&quot;, &quot;age&quot;, &quot;gender&quot;, all_cols100, &quot;age2&quot;, &quot;inventory&quot;)) %&gt;% gather(key = item, value = value, -RID, -age, -gender, -inventory, na.rm = T) ) %&gt;% tbl_df %&gt;% separate(item, c(&quot;trait&quot;, &quot;number&quot;), 1, remove = F) %&gt;% select(inventory, RID, age, trait, item, value) %&gt;% group_by(inventory, age, trait) %&gt;% nest() %&gt;% mutate(data = map(data, function(x){x %&gt;% spread(key = item, value = value)}), cols = map(data, colnames), results = map(data, EDBqgraph2), mat = map(results, ~.[[1]]), net = map(results, ~.[[2]]), centrality = map(net, centrality_auto)) save(ST_net_nested, file = &quot;~/Box/networks/SAPA/st_nested_nets.RData&quot;) load(&quot;~/Box/networks/SAPA/st_nested_nets.RData&quot;) ST_net_nested &lt;- ST_net_nested %&gt;% mutate(edges.df = map2(net, cols, getEdges.df), cors.df = map2(mat, cols, getEdges.df)) "],
["pcors.html", "Chapter 5 Age Differences in Coherence and Differentiation 5.1 Multi-Trait Coherence and Differentiation 5.2 Single and Mutli-Trait Coherence", " Chapter 5 Age Differences in Coherence and Differentiation trait.edges.sum &lt;- ST_net_nested %&gt;% unnest(edges.df) %&gt;% group_by(inventory, age, Trait) %&gt;% summarize(mean = fisherz2r(mean(fisherz(abs(weight)), na.rm = T))) %&gt;% ungroup() %&gt;% group_by(age) %&gt;% mutate(type = &quot;Single Trait&quot;, comp = &quot;ST-Coherence&quot;, gmean = fisherz2r(mean(fisherz(mean), na.rm = T)), traits = Trait) trait.edges.sum50 &lt;- trait.edges.sum %&gt;% filter(inventory == &quot;IPIP50&quot;) edges.sum &lt;- MT_net_nested %&gt;% unnest(edges.df) %&gt;% separate(from, c(&quot;from_trait&quot;, &quot;from_item&quot;), 1) %&gt;% separate(to, c(&quot;to_trait&quot;, &quot;to_item&quot;), 1) %&gt;% unite(traits, from_trait, to_trait, remove = F) %&gt;% mutate(comp = ifelse(from_trait == to_trait, &quot;Coherence&quot;, &quot;Differentiation&quot;)) %&gt;% group_by(inventory, age, traits, comp, from_trait, to_trait) %&gt;% summarize(n = n(), mean = fisherz2r(mean(fisherz(abs(weight)), na.rm = T))) %&gt;% ungroup() %&gt;% group_by(inventory, age, from_trait, comp) %&gt;% mutate(traitMean1 = fisherz2r(mean(fisherz(mean), na.rm = T))) %&gt;% ungroup() %&gt;% group_by(inventory, age, to_trait, comp) %&gt;% mutate(traitMean2 = fisherz2r(mean(fisherz(mean), na.rm = T))) %&gt;% ungroup() %&gt;% mutate(traitMean = fisherz2r(rowMeans(cbind(fisherz(traitMean1), fisherz(traitMean2)), na.rm = T))) %&gt;% ungroup() %&gt;% group_by(inventory, age, comp) %&gt;% mutate(type = &quot;Multi Trait&quot;, gmean = fisherz2r(mean(fisherz(mean), na.rm = T))) %&gt;% arrange(age, comp, from_trait) %&gt;% mutate(Trait = ifelse(comp == &quot;Coherence&quot;, toupper(from_trait), NA)) edges.sum$traitMean &lt;- with(edges.sum, rowMeans(cbind(traitMean1, traitMean2), na.rm = T)) 5.1 Multi-Trait Coherence and Differentiation edges.sum %&gt;% full_join(trait.edges.sum) %&gt;% filter(inventory == &quot;IPIP50&quot;) %&gt;% ggplot(aes(x = as.numeric(age), y = mean)) + geom_smooth(data = edges.sum %&gt;% filter(inventory == &quot;IPIP50&quot;), span = .3, aes(group = traits), alpha = .1, color = &quot;gray&quot;, size = .2, se = F) + geom_smooth(data = edges.sum %&gt;% filter(inventory == &quot;IPIP50&quot;), size = 1, aes(y = gmean, group = comp, color = comp), se = F, span = .3) + # geom_line(data = trait.edges.sum %&gt;% filter(inventory == &quot;IPIP50&quot;), # aes(group = traits), alpha = .1) + # geom_line(data = trait.edges.sum %&gt;% filter(inventory == &quot;IPIP50&quot;), size = 1, # aes(y = gmean, group = comp, color = comp)) + scale_x_continuous(limits = c(14,80), breaks = seq(15,80,5)) + scale_y_continuous(limits = c(0,.2), breaks = seq(0,.2, .05)) + scale_linetype_manual(values = c(&quot;solid&quot;, &quot;dashed&quot;)) + scale_color_manual(values = c(&quot;royalblue1&quot;, &quot;mediumseagreen&quot;)) + labs(x = &quot;Age&quot;, y = &quot;Average Edge Weight&quot;, color = NULL) + guides(linetype = F) + theme_classic() + theme(axis.text.x = element_text(size = rel(.75), face = &quot;bold&quot;, angle = 90), axis.text.y = element_text(face = &quot;bold&quot;), legend.key.size = unit(.4, &quot;cm&quot;), legend.text = element_text(size = rel(.7)), legend.title = element_text(size = rel(.7), face = &quot;bold&quot;), legend.position = c(.15, .9)) ## Joining, by = c(&quot;inventory&quot;, &quot;age&quot;, &quot;traits&quot;, &quot;comp&quot;, &quot;mean&quot;, &quot;type&quot;, &quot;gmean&quot;, &quot;Trait&quot;) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; ggsave(&quot;~/Box/networks/SAPA/photos/differentiation_coherence_line_graph.png&quot;, width = 5, height = 4) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 5.2 Single and Mutli-Trait Coherence edges.sum %&gt;% full_join(trait.edges.sum) %&gt;% filter(comp != &quot;Differentiation&quot; &amp; inventory == &quot;IPIP50&quot;) %&gt;% ggplot(aes(x = as.numeric(age), y = mean, group = comp)) + geom_line(data = filter(edges.sum, comp == &quot;Coherence&quot; &amp; inventory == &quot;IPIP50&quot;), aes(color = Trait, linetype = type)) + geom_line(data = trait.edges.sum %&gt;% filter(inventory == &quot;IPIP50&quot;), aes(color = Trait, linetype = type)) + scale_x_continuous(limits = c(14,80), breaks = seq(15, 80,5)) + scale_linetype_manual(values = c(&quot;dotted&quot;, &quot;solid&quot;)) + guides(color = F) + facet_wrap(~Trait, nrow = 3) + labs(x = &quot;Age&quot;, y = &quot;Average Edge Weight&quot;, color = &quot;Big5\\nTrait&quot;, linetype = &quot;Network\\nType&quot;) + theme_classic() + theme(axis.text.x = element_text(size = rel(.5), face = &quot;bold&quot;, angle = 90), axis.text.y = element_text(face = &quot;bold&quot;), legend.position = c(.75,.15), legend.key.size = unit(.5, &quot;cm&quot;), legend.text = element_text(size = rel(.75)), legend.title = element_text(size = rel(.75), face = &quot;bold&quot;)) ## Joining, by = c(&quot;inventory&quot;, &quot;age&quot;, &quot;traits&quot;, &quot;comp&quot;, &quot;mean&quot;, &quot;type&quot;, &quot;gmean&quot;, &quot;Trait&quot;) ggsave(&quot;~/Box/networks/SAPA/photos/by_trait_differentiation_coherence_line_graph.png&quot;, width = 5, height = 4) "],
["communities.html", "Chapter 6 Community Structure", " Chapter 6 Community Structure Next, we calculate the communities in each network using the Spin Glass algorithm. Although there is no widely accepted definition of communities (Baroncelli, 2012), communities are generally considered to be nodes that are more connected to each other than to other nodes. For demonstrative purposes, we separately collapse across the 20s and 60s and run the networks. Then we calculate their community structure and compare them. ## Multi-Trait ### Run Communities communities_fun &lt;- function(g, cols){ g &lt;- igraph::as.igraph(g) V(g)$label &lt;- cols g2 &lt;- g E(g2)$weight &lt;- abs(E(g2)$weight) lvc &lt;- igraph::cluster_louvain(g2) subgraphs &lt;- list() for (i in 1:length(unique(lvc$membership))){ subgraphs[[i]] &lt;- igraph::induced_subgraph(g, vids = which(lvc$membership == i), impl = &quot;copy_and_delete&quot;)} results &lt;- list(graph = g, louvain = lvc, subgraphs = subgraphs) return(results) } membership_fun &lt;- function(comm, cols){ comm &lt;- comm$louvain$membership %&gt;% setNames(cols) } MT_net_nested &lt;- MT_net_nested %&gt;% mutate(communities = map2(net, cols, communities_fun), membership = map2(communities, cols, possibly(membership_fun, NA_real_))) MT_net_nested_gr &lt;- MT_net_nested_gr %&gt;% mutate(communities = map2(net, cols, communities_fun), membership = map2(communities, cols, membership_fun)) communitiesall &lt;- (MT_net_nested %&gt;% filter(inventory == &quot;IPIP50&quot;))$membership %&gt;% ldply(.) communities38below &lt;- (MT_net_nested %&gt;% filter(inventory == &quot;IPIP50&quot; &amp; age &lt;= 38))$membership %&gt;% ldply(.) communities39above &lt;- (MT_net_nested %&gt;% filter(inventory == &quot;IPIP50&quot; &amp; age &gt;= 39))$membership %&gt;% ldply(.) 6.0.1 Plots communities20s &lt;- (MT_net_nested_gr %&gt;% filter(inventory == &quot;IPIP50&quot; &amp; age_group == 2))$communities[[1]] communities60s &lt;- (MT_net_nested_gr %&gt;% filter(inventory == &quot;IPIP50&quot; &amp; age_group == 6))$communities[[1]] b_color_fun &lt;- function(c){ mapvalues(c$louvain$membership, from = seq(1, max(c$louvain$membership),1), to = RColorBrewer::brewer.pal(max(c$louvain$membership),&quot;Set3&quot;)) } MT_net_nested_gr &lt;- MT_net_nested_gr %&gt;% mutate(bordercolors = map(communities, b_color_fun), net = map2(net, bordercolors, EDBqgraph_communities)) %&gt;% arrange(age_group) # pdf(filename = sprintf(&quot;%s/SAPA/photos/nets_20s_60s.bmp&quot;, data_path), width = 800, height = 400) par(mfrow = c(1,2)) plot((MT_net_nested_gr %&gt;% filter(inventory == &quot;IPIP50&quot; &amp; age_group == 2))$net[[1]]) title(&quot;20s&quot;) plot((MT_net_nested_gr %&gt;% filter(inventory == &quot;IPIP50&quot; &amp; age_group == 6))$net[[1]]) title(&quot;60s&quot;) # dev.off() par(mfrow = c(2,4)) lapply(1:7, function(x){ plot((MT_net_nested_gr %&gt;% filter(inventory == &quot;IPIP50&quot;))$net[[x]]); title(sprintf(&quot;%s0s&quot;, x))}) ## [[1]] ## NULL ## ## [[2]] ## NULL ## ## [[3]] ## NULL ## ## [[4]] ## NULL ## ## [[5]] ## NULL ## ## [[6]] ## NULL ## ## [[7]] ## NULL 6.0.2 Matching Across Communities The code below is a little incomprehensible, but in this instance there isn’t really a better alternative. match_mat &lt;- matrix(rep(NA, 50*50), nrow = 50) for(i in 1:50){ # for(j in 1:50){ match &lt;- 0L for(k in 1:50){ match &lt;- ifelse(communitiesall[k,i] == communitiesall[k,j], match + 1, match) } match_mat[i,j] &lt;- match } } match_mat38below &lt;- matrix(rep(NA, 50*50), nrow = 50) match_mat39above &lt;- matrix(rep(NA, 50*50), nrow = 50) for(i in 1:50){ for(j in 1:50){ match38below &lt;- 0L match39above &lt;- 0L for(k in 1:25){ match38below &lt;- ifelse(communities38below[k,i] == communities38below[k,j], match38below + 1, match38below) match39above &lt;- ifelse(communities39above[k,i] == communities39above[k,j], match39above + 1, match39above) } match_mat38below[i,j] &lt;- match38below match_mat39above[i,j] &lt;- match39above } } community_plot_fun &lt;- function(df, age, lim){ colnames(df) &lt;- all_cols50; rownames(df) &lt;- all_cols50 df[upper.tri(df, diag = T)] &lt;- NA tbl_df(df) %&gt;% mutate(Edge1 = factor(all_cols50, levels = all_cols50)) %&gt;% gather(key = Edge2, value = communities, 1:50) %&gt;% mutate(Edge2 = factor(Edge2, levels = all_cols50)) %&gt;% filter(!is.na(communities)) %&gt;% ggplot(aes(x = Edge2, y = Edge1, fill = communities)) + geom_raster() + scale_fill_gradient( high = &quot;orchid4&quot;, low = &quot;white&quot;, limit = c(0,lim), name=&quot;Shared\\nCommunity\\nSums&quot;) + labs(x = NULL, y = NULL, title = sprintf(&quot;%s&quot;, age)) + theme_classic() + theme(axis.text.x = element_text(face = &quot;bold&quot;, angle = 90), axis.text.y = element_text(face = &quot;bold&quot;), plot.title = element_text(hjust = .5, face = &quot;bold&quot;)) } communityall &lt;- community_plot_fun(match_mat, &quot;All&quot;, 50) + theme(legend.position = c(.9, .5)) community38below &lt;- community_plot_fun(match_mat38below, &quot;38 &amp; below&quot;, 25) + theme(legend.position = &quot;none&quot;, axis.text = element_text(size = rel(.3))) community39above &lt;- community_plot_fun(match_mat39above, &quot;39 &amp; above&quot;, 25) + theme(legend.position = &quot;none&quot;, axis.text = element_text(size = rel(.3))) community_plot &lt;- grid.arrange(communityall, community38below, community39above, layout_matrix = rbind(c(1,1,3), c(1,1,4))) ggsave(plot = community_plot, file = &quot;~/Box/networks/SAPA/photos/shared_communities.png&quot;, width = 9, height = 6) "],
["procors.html", "Chapter 7 Profile Correlations 7.1 Profiles Correlation Plots (Figure 5)", " Chapter 7 Profile Correlations Next, we calculate profile correlations to test the stability of edges across all possible pairwise combinations of ages. A strong parallel correlation indicates that the weight of the edges is associated across two ages. We then map these profile correlations onto a heat map that displays the pairwise profile correlations. We would expect to see the strongest profile correlations cluster on the diagonal of heatmap – that is between ages that are adjacent or near in age. ## Multi-Trait wide_fun &lt;- function(df){ df &lt;- unclass(df) %&gt;% data.frame %&gt;% select(-from, -to) %&gt;% spread(key = edge, value = weight) rownames(df) &lt;- df$age df &lt;- df %&gt;% select(-age) return(df) } # change the direction of the data MT_procor &lt;- MT_net_nested %&gt;% unnest(edges.df) %&gt;% group_by(inventory) %&gt;% nest() %&gt;% mutate(wide = map(data, wide_fun), procor = map(wide, ~cor(t(.), use = &quot;pairwise.complete.obs&quot;))) # separate out differentiation from coherence edges.mat50bw &lt;- MT_net_nested %&gt;% filter(inventory == &quot;IPIP50&quot;) %&gt;% unnest(edges.df) %&gt;% separate(from, into = c(&quot;from_factor&quot;, &quot;from_item&quot;), 1) %&gt;% separate(to, into = c(&quot;to_factor&quot;, &quot;to_item&quot;), 1) %&gt;% filter(from_factor != to_factor) %&gt;% select(age, weight, edge) %&gt;% spread(key = edge, value = weight) %&gt;% unclass %&gt;% data.frame # separate out coherence from differentiation edges.mat50wi &lt;- MT_net_nested %&gt;% filter(inventory == &quot;IPIP50&quot;) %&gt;% unnest(edges.df) %&gt;% separate(from, into = c(&quot;from_factor&quot;, &quot;from_item&quot;), 1) %&gt;% separate(to, into = c(&quot;to_factor&quot;, &quot;to_item&quot;), 1) %&gt;% filter(from_factor == to_factor) %&gt;% select(age, weight, edge) %&gt;% spread(key = edge, value = weight) %&gt;% unclass %&gt;% data.frame # set the rownsames of these to age rownames(edges.mat50bw) &lt;- edges.mat50bw$age rownames(edges.mat50wi) &lt;- edges.mat50wi$age ############################################## ############ Profile Correlations ############ ############################################## # calculate profile correlations procor50bw &lt;- cor(t(edges.mat50bw[,-1]), use = &quot;pairwise.complete.obs&quot;) procor50wi &lt;- cor(t(edges.mat50wi[,-1]), use = &quot;pairwise.complete.obs&quot;) 7.1 Profiles Correlation Plots (Figure 5) ############################################## ################## PLOTS ##################### ############################################## procor_plot_fun &lt;- function(df, inv, leg){ df[upper.tri(df, diag = T)] &lt;- NA p &lt;- tbl_df(df) %&gt;% mutate(age1 = colnames(.)) %&gt;% gather(key = age2, value = r, 1:(ncol(.) - 1)) %&gt;% filter(!is.na(r)) %&gt;% ggplot(aes(x = age2, y = age1, fill = r)) + geom_raster(aes(fill = r)) + scale_fill_gradient2(low = &quot;blue&quot;, high = &quot;red&quot;, mid = &quot;white&quot;, midpoint = .5, limit = c(0,1), space = &quot;Lab&quot;, name=&quot;Profile\\nCorrelation&quot;) + labs(x = &quot;Age&quot;, y = &quot;Age&quot;, title = sprintf(&quot;Profile Correlations for %s&quot;, inv)) + theme_classic() + theme(legend.position = leg, axis.text = element_text(face = &quot;bold&quot;), axis.text.x = element_text(angle = 90, size = rel(.8)), plot.title = element_text(hjust = .5)) ggsave(p, file = sprintf(&quot;%s/SAPA/photos/profile correlations/Big5_%s_profile_cors_heatmap.png&quot;, data_path, inv), width = 12, height = 8) p } MT_procor &lt;- MT_procor %&gt;% mutate(plot = map2(procor, inventory, ~procor_plot_fun(.x, .y, leg = &quot;none&quot;))) layout &lt;- rbind(c(1, 1, 2), c(1, 1, 3)) p &lt;- gridExtra::grid.arrange( MT_procor$plot[[2]], procor_plot_fun(procor50bw, &quot;IPIP50 Cross-Trait Edges&quot;, leg = &quot;none&quot;), procor_plot_fun(procor50wi, &quot;IPIP50 Within-Trait Edges&quot;, leg = &quot;none&quot;), layout_matrix = layout) ggsave(p, file = sprintf(&quot;%s/SAPA/photos/profile correlations/Big5_IPIP50_profile_cors_heatmap.png&quot;, data_path), width = 12, height = 8) "]
]
